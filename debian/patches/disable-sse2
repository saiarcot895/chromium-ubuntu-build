description: don't set sse2 compiler flags on i386
author: Michael Gilbert <mgilbert@debian.org>
debian-bug: http://bugs.debian.org/750361

Index: beta/cc/raster/texture_compressor.cc
===================================================================
--- beta.orig/cc/raster/texture_compressor.cc
+++ beta/cc/raster/texture_compressor.cc
@@ -8,7 +8,7 @@
 #include "base/memory/ptr_util.h"
 #include "cc/raster/texture_compressor_etc1.h"
 
-#if defined(ARCH_CPU_X86_FAMILY)
+#if defined(ARCH_CPU_X86_64)
 #include "base/cpu.h"
 #include "cc/raster/texture_compressor_etc1_sse.h"
 #endif
@@ -18,7 +18,7 @@ namespace cc {
 std::unique_ptr<TextureCompressor> TextureCompressor::Create(Format format) {
   switch (format) {
     case kFormatETC1: {
-#if defined(ARCH_CPU_X86_FAMILY)
+#if defined(ARCH_CPU_X86_64)
       base::CPU cpu;
       if (cpu.has_sse2()) {
         return base::WrapUnique(new TextureCompressorETC1SSE());
Index: beta/media/base/sinc_resampler.cc
===================================================================
--- beta.orig/media/base/sinc_resampler.cc
+++ beta/media/base/sinc_resampler.cc
@@ -84,7 +84,7 @@
 #include "base/logging.h"
 #include "build/build_config.h"
 
-#if defined(ARCH_CPU_X86_FAMILY)
+#if defined(__x86_64__)
 #include <xmmintrin.h>
 #define CONVOLVE_FUNC Convolve_SSE
 #elif defined(ARCH_CPU_ARM_FAMILY) && defined(USE_NEON)
@@ -328,7 +328,7 @@ float SincResampler::Convolve_C(const fl
       kernel_interpolation_factor * sum2);
 }
 
-#if defined(ARCH_CPU_X86_FAMILY)
+#if defined(__x86_64__)
 float SincResampler::Convolve_SSE(const float* input_ptr, const float* k1,
                                   const float* k2,
                                   double kernel_interpolation_factor) {
Index: beta/media/base/sinc_resampler.h
===================================================================
--- beta.orig/media/base/sinc_resampler.h
+++ beta/media/base/sinc_resampler.h
@@ -96,7 +96,7 @@ class MEDIA_EXPORT SincResampler {
   // ARM, NEON support is chosen at compile time based on compilation flags.
   static float Convolve_C(const float* input_ptr, const float* k1,
                           const float* k2, double kernel_interpolation_factor);
-#if defined(ARCH_CPU_X86_FAMILY)
+#if defined(__x86_64__)
   static float Convolve_SSE(const float* input_ptr, const float* k1,
                             const float* k2,
                             double kernel_interpolation_factor);
Index: beta/media/base/sinc_resampler_perftest.cc
===================================================================
--- beta.orig/media/base/sinc_resampler_perftest.cc
+++ beta/media/base/sinc_resampler_perftest.cc
@@ -22,7 +22,7 @@ static const double kKernelInterpolation
 static void DoNothing(int frames, float* destination) {}
 
 // Define platform independent function name for Convolve* tests.
-#if defined(ARCH_CPU_X86_FAMILY)
+#if defined(__x86_64__)
 #define CONVOLVE_FUNC Convolve_SSE
 #elif defined(ARCH_CPU_ARM_FAMILY) && defined(USE_NEON)
 #define CONVOLVE_FUNC Convolve_NEON
Index: beta/media/base/sinc_resampler_unittest.cc
===================================================================
--- beta.orig/media/base/sinc_resampler_unittest.cc
+++ beta/media/base/sinc_resampler_unittest.cc
@@ -153,7 +153,7 @@ TEST(SincResamplerTest, DISABLED_SetRati
 
 
 // Define platform independent function name for Convolve* tests.
-#if defined(ARCH_CPU_X86_FAMILY)
+#if defined(__x86_64__)
 #define CONVOLVE_FUNC Convolve_SSE
 #elif defined(ARCH_CPU_ARM_FAMILY) && defined(USE_NEON)
 #define CONVOLVE_FUNC Convolve_NEON
Index: beta/media/base/vector_math.cc
===================================================================
--- beta.orig/media/base/vector_math.cc
+++ beta/media/base/vector_math.cc
@@ -11,7 +11,7 @@
 #include "build/build_config.h"
 
 // NaCl does not allow intrinsics.
-#if defined(ARCH_CPU_X86_FAMILY) && !defined(OS_NACL)
+#if defined(__x86_64__) && !defined(OS_NACL)
 #include <xmmintrin.h>
 // Don't use custom SSE versions where the auto-vectorized C version performs
 // better, which is anywhere clang is used.
@@ -89,7 +89,7 @@ std::pair<float, float> EWMAAndMaxPower_
   return result;
 }
 
-#if defined(ARCH_CPU_X86_FAMILY) && !defined(OS_NACL)
+#if defined(__x86_64__) && !defined(OS_NACL)
 void FMUL_SSE(const float src[], float scale, int len, float dest[]) {
   const int rem = len % 4;
   const int last_index = len - rem;
Index: beta/media/base/vector_math_perftest.cc
===================================================================
--- beta.orig/media/base/vector_math_perftest.cc
+++ beta/media/base/vector_math_perftest.cc
@@ -83,7 +83,7 @@ class VectorMathPerfTest : public testin
 };
 
 // Define platform dependent function names for SIMD optimized methods.
-#if defined(ARCH_CPU_X86_FAMILY)
+#if defined(__x86_64__)
 #define FMAC_FUNC FMAC_SSE
 #define FMUL_FUNC FMUL_SSE
 #define EWMAAndMaxPower_FUNC EWMAAndMaxPower_SSE
Index: beta/media/base/vector_math_testing.h
===================================================================
--- beta.orig/media/base/vector_math_testing.h
+++ beta/media/base/vector_math_testing.h
@@ -19,7 +19,7 @@ MEDIA_EXPORT void FMUL_C(const float src
 MEDIA_EXPORT std::pair<float, float> EWMAAndMaxPower_C(
     float initial_value, const float src[], int len, float smoothing_factor);
 
-#if defined(ARCH_CPU_X86_FAMILY) && !defined(OS_NACL)
+#if defined(__x86_64__) && !defined(OS_NACL)
 MEDIA_EXPORT void FMAC_SSE(const float src[], float scale, int len,
                            float dest[]);
 MEDIA_EXPORT void FMUL_SSE(const float src[], float scale, int len,
Index: beta/media/base/vector_math_unittest.cc
===================================================================
--- beta.orig/media/base/vector_math_unittest.cc
+++ beta/media/base/vector_math_unittest.cc
@@ -76,7 +76,7 @@ TEST_F(VectorMathTest, FMAC) {
     VerifyOutput(kResult);
   }
 
-#if defined(ARCH_CPU_X86_FAMILY)
+#if defined(__x86_64__)
   {
     SCOPED_TRACE("FMAC_SSE");
     FillTestVectors(kInputFillValue, kOutputFillValue);
@@ -117,7 +117,7 @@ TEST_F(VectorMathTest, FMUL) {
     VerifyOutput(kResult);
   }
 
-#if defined(ARCH_CPU_X86_FAMILY)
+#if defined(__x86_64__)
   {
     SCOPED_TRACE("FMUL_SSE");
     FillTestVectors(kInputFillValue, kOutputFillValue);
@@ -225,7 +225,7 @@ class EWMATestScenario {
       EXPECT_NEAR(expected_max_, result.second, 0.0000001f);
     }
 
-#if defined(ARCH_CPU_X86_FAMILY)
+#if defined(__x86_64__)
     {
       SCOPED_TRACE("EWMAAndMaxPower_SSE");
       const std::pair<float, float>& result = vector_math::EWMAAndMaxPower_SSE(
Index: beta/skia/ext/convolver.h
===================================================================
--- beta.orig/skia/ext/convolver.h
+++ beta/skia/ext/convolver.h
@@ -17,7 +17,6 @@
 // We can build SSE2 optimized versions for all x86 CPUs
 // except when building for the IOS emulator.
 #if defined(ARCH_CPU_X86_FAMILY) && !defined(OS_IOS)
-#define SIMD_SSE2 1
 #define SIMD_PADDING 8  // 8 * int16_t
 #endif
 
Index: beta/third_party/WebKit/Source/platform/audio/DirectConvolver.cpp
===================================================================
--- beta.orig/third_party/WebKit/Source/platform/audio/DirectConvolver.cpp
+++ beta/third_party/WebKit/Source/platform/audio/DirectConvolver.cpp
@@ -35,7 +35,7 @@
 #include "platform/audio/VectorMath.h"
 #include "platform/wtf/CPU.h"
 
-#if (CPU(X86) || CPU(X86_64)) && !OS(MACOSX)
+#if (CPU(X86_64)) && !OS(MACOSX)
 #include <emmintrin.h>
 #endif
 
@@ -83,7 +83,7 @@ void DirectConvolver::Process(AudioFloat
 #endif  // CPU(X86)
 #else
   size_t i = 0;
-#if CPU(X86) || CPU(X86_64)
+#if CPU(X86_64)
   // Convolution using SSE2. Currently only do this if both |kernelSize| and
   // |framesToProcess| are multiples of 4. If not, use the straightforward loop
   // below.
@@ -397,7 +397,7 @@ void DirectConvolver::Process(AudioFloat
       }
       dest_p[i++] = sum;
     }
-#if CPU(X86) || CPU(X86_64)
+#if CPU(X86_64)
   }
 #endif
 #endif  // OS(MACOSX)
Index: beta/third_party/WebKit/Source/platform/audio/SincResampler.cpp
===================================================================
--- beta.orig/third_party/WebKit/Source/platform/audio/SincResampler.cpp
+++ beta/third_party/WebKit/Source/platform/audio/SincResampler.cpp
@@ -31,7 +31,7 @@
 #include "platform/wtf/CPU.h"
 #include "platform/wtf/MathExtras.h"
 
-#if CPU(X86) || CPU(X86_64)
+#if CPU(X86_64)
 #include <emmintrin.h>
 #endif
 
@@ -273,7 +273,7 @@ void SincResampler::Process(AudioSourceP
       {
         float input;
 
-#if CPU(X86) || CPU(X86_64)
+#if CPU(X86_64)
         // If the sourceP address is not 16-byte aligned, the first several
         // frames (at most three) should be processed seperately.
         while ((reinterpret_cast<uintptr_t>(input_p) & 0x0F) && n) {
Index: beta/third_party/WebKit/Source/platform/audio/VectorMath.cpp
===================================================================
--- beta.orig/third_party/WebKit/Source/platform/audio/VectorMath.cpp
+++ beta/third_party/WebKit/Source/platform/audio/VectorMath.cpp
@@ -34,7 +34,7 @@
 #include <Accelerate/Accelerate.h>
 #endif
 
-#if CPU(X86) || CPU(X86_64)
+#if CPU(X86_64)
 #include <emmintrin.h>
 #endif
 
@@ -176,7 +176,7 @@ void Vsma(const float* source_p,
           size_t frames_to_process) {
   int n = frames_to_process;
 
-#if CPU(X86) || CPU(X86_64)
+#if CPU(X86_64)
   if ((source_stride == 1) && (dest_stride == 1)) {
     float k = *scale;
 
@@ -274,7 +274,7 @@ void Vsmul(const float* source_p,
            size_t frames_to_process) {
   int n = frames_to_process;
 
-#if CPU(X86) || CPU(X86_64)
+#if CPU(X86_64)
   if ((source_stride == 1) && (dest_stride == 1)) {
     float k = *scale;
 
@@ -363,7 +363,7 @@ void Vsmul(const float* source_p,
       source_p += source_stride;
       dest_p += dest_stride;
     }
-#if CPU(X86) || CPU(X86_64)
+#if CPU(X86_64)
   }
 #endif
 }
@@ -377,7 +377,7 @@ void Vadd(const float* source1p,
           size_t frames_to_process) {
   int n = frames_to_process;
 
-#if CPU(X86) || CPU(X86_64)
+#if CPU(X86_64)
   if ((source_stride1 == 1) && (source_stride2 == 1) && (dest_stride == 1)) {
     // If the sourceP address is not 16-byte aligned, the first several frames
     // (at most three) should be processed separately.
@@ -504,7 +504,7 @@ void Vadd(const float* source1p,
       source2p += source_stride2;
       dest_p += dest_stride;
     }
-#if CPU(X86) || CPU(X86_64)
+#if CPU(X86_64)
   }
 #endif
 }
@@ -518,7 +518,7 @@ void Vmul(const float* source1p,
           size_t frames_to_process) {
   int n = frames_to_process;
 
-#if CPU(X86) || CPU(X86_64)
+#if CPU(X86_64)
   if ((source_stride1 == 1) && (source_stride2 == 1) && (dest_stride == 1)) {
     // If the source1P address is not 16-byte aligned, the first several frames
     // (at most three) should be processed separately.
@@ -618,7 +618,7 @@ void Zvmul(const float* real1p,
            float* imag_dest_p,
            size_t frames_to_process) {
   unsigned i = 0;
-#if CPU(X86) || CPU(X86_64)
+#if CPU(X86_64)
   // Only use the SSE optimization in the very common case that all addresses
   // are 16-byte aligned.  Otherwise, fall through to the scalar code below.
   if (!(reinterpret_cast<uintptr_t>(real1p) & 0x0F) &&
@@ -677,7 +677,7 @@ void Vsvesq(const float* source_p,
   int n = frames_to_process;
   float sum = 0;
 
-#if CPU(X86) || CPU(X86_64)
+#if CPU(X86_64)
   if (source_stride == 1) {
     // If the sourceP address is not 16-byte aligned, the first several frames
     // (at most three) should be processed separately.
@@ -746,7 +746,7 @@ void Vmaxmgv(const float* source_p,
   int n = frames_to_process;
   float max = 0;
 
-#if CPU(X86) || CPU(X86_64)
+#if CPU(X86_64)
   if (source_stride == 1) {
     // If the sourceP address is not 16-byte aligned, the first several frames
     // (at most three) should be processed separately.
Index: beta/third_party/WebKit/Source/platform/graphics/cpu/x86/WebGLImageConversionSSE.h
===================================================================
--- beta.orig/third_party/WebKit/Source/platform/graphics/cpu/x86/WebGLImageConversionSSE.h
+++ beta/third_party/WebKit/Source/platform/graphics/cpu/x86/WebGLImageConversionSSE.h
@@ -5,7 +5,7 @@
 #ifndef WebGLImageConversionSSE_h
 #define WebGLImageConversionSSE_h
 
-#if CPU(X86) || CPU(X86_64)
+#if CPU(X86_64)
 
 #include <emmintrin.h>
 
Index: beta/third_party/WebKit/Source/platform/graphics/gpu/WebGLImageConversion.cpp
===================================================================
--- beta.orig/third_party/WebKit/Source/platform/graphics/gpu/WebGLImageConversion.cpp
+++ beta/third_party/WebKit/Source/platform/graphics/gpu/WebGLImageConversion.cpp
@@ -442,7 +442,7 @@ void Unpack<WebGLImageConversion::kDataF
   const uint32_t* source32 = reinterpret_cast_ptr<const uint32_t*>(source);
   uint32_t* destination32 = reinterpret_cast_ptr<uint32_t*>(destination);
 
-#if CPU(X86) || CPU(X86_64)
+#if CPU(X86_64)
   SIMD::UnpackOneRowOfBGRA8LittleToRGBA8(source32, destination32,
                                          pixels_per_row);
 #endif
@@ -470,7 +470,7 @@ void Unpack<WebGLImageConversion::kDataF
     const uint16_t* source,
     uint8_t* destination,
     unsigned pixels_per_row) {
-#if CPU(X86) || CPU(X86_64)
+#if CPU(X86_64)
   SIMD::UnpackOneRowOfRGBA5551LittleToRGBA8(source, destination,
                                             pixels_per_row);
 #endif
@@ -500,7 +500,7 @@ void Unpack<WebGLImageConversion::kDataF
     const uint16_t* source,
     uint8_t* destination,
     unsigned pixels_per_row) {
-#if CPU(X86) || CPU(X86_64)
+#if CPU(X86_64)
   SIMD::UnpackOneRowOfRGBA4444LittleToRGBA8(source, destination,
                                             pixels_per_row);
 #endif
@@ -716,7 +716,7 @@ void Pack<WebGLImageConversion::kDataFor
           uint8_t>(const uint8_t* source,
                    uint8_t* destination,
                    unsigned pixels_per_row) {
-#if CPU(X86) || CPU(X86_64)
+#if CPU(X86_64)
   SIMD::PackOneRowOfRGBA8LittleToR8(source, destination, pixels_per_row);
 #endif
 #if HAVE(MIPS_MSA_INTRINSICS)
@@ -773,7 +773,7 @@ void Pack<WebGLImageConversion::kDataFor
           uint8_t>(const uint8_t* source,
                    uint8_t* destination,
                    unsigned pixels_per_row) {
-#if CPU(X86) || CPU(X86_64)
+#if CPU(X86_64)
   SIMD::PackOneRowOfRGBA8LittleToRA8(source, destination, pixels_per_row);
 #endif
 #if HAVE(MIPS_MSA_INTRINSICS)
@@ -885,7 +885,7 @@ void Pack<WebGLImageConversion::kDataFor
           uint8_t>(const uint8_t* source,
                    uint8_t* destination,
                    unsigned pixels_per_row) {
-#if CPU(X86) || CPU(X86_64)
+#if CPU(X86_64)
   SIMD::PackOneRowOfRGBA8LittleToRGBA8(source, destination, pixels_per_row);
 #endif
 #if HAVE(MIPS_MSA_INTRINSICS)
Index: beta/third_party/WebKit/Source/modules/webaudio/AudioParamTimeline.cpp
===================================================================
--- beta.orig/third_party/WebKit/Source/modules/webaudio/AudioParamTimeline.cpp
+++ beta/third_party/WebKit/Source/modules/webaudio/AudioParamTimeline.cpp
@@ -32,7 +32,7 @@
 #include "platform/wtf/MathExtras.h"
 #include "platform/wtf/PtrUtil.h"
 
-#if CPU(X86) || CPU(X86_64)
+#if CPU(X86_64)
 #include <emmintrin.h>
 #endif
 
@@ -1289,7 +1289,7 @@ std::tuple<size_t, float, unsigned> Audi
     size_t current_frame,
     float value,
     unsigned write_index) {
-#if CPU(X86) || CPU(X86_64)
+#if CPU(X86_64)
   auto number_of_values = current_state.number_of_values;
 #endif
   auto fill_to_frame = current_state.fill_to_frame;
@@ -1302,7 +1302,7 @@ std::tuple<size_t, float, unsigned> Audi
   double delta_time = time2 - time1;
   float k = delta_time > 0 ? 1 / delta_time : 0;
   const float value_delta = value2 - value1;
-#if CPU(X86) || CPU(X86_64)
+#if CPU(X86_64)
   if (fill_to_frame > write_index) {
     // Minimize in-loop operations. Calculate starting value and increment.
     // Next step: value += inc.
@@ -1430,7 +1430,7 @@ std::tuple<size_t, float, unsigned> Audi
     size_t current_frame,
     float value,
     unsigned write_index) {
-#if CPU(X86) || CPU(X86_64)
+#if CPU(X86_64)
   auto number_of_values = current_state.number_of_values;
 #endif
   auto fill_to_frame = current_state.fill_to_frame;
@@ -1481,7 +1481,7 @@ std::tuple<size_t, float, unsigned> Audi
     for (; write_index < fill_to_frame; ++write_index)
       values[write_index] = target;
   } else {
-#if CPU(X86) || CPU(X86_64)
+#if CPU(X86_64)
     if (fill_to_frame > write_index) {
       // Resolve recursion by expanding constants to achieve a 4-step
       // loop unrolling.
@@ -1615,7 +1615,7 @@ std::tuple<size_t, float, unsigned> Audi
   // Oversampled curve data can be provided if sharp discontinuities are
   // desired.
   unsigned k = 0;
-#if CPU(X86) || CPU(X86_64)
+#if CPU(X86_64)
   if (fill_to_frame > write_index) {
     const __m128 v_curve_virtual_index = _mm_set_ps1(curve_virtual_index);
     const __m128 v_curve_points_per_frame = _mm_set_ps1(curve_points_per_frame);
